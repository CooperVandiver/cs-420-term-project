{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370d2cd-a814-40f4-97c4-8c98c70455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"facebook/opt-1.3b\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fb732-6d53-43e2-8b42-5647740c66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93e2b4-4993-4cfb-9adb-56e633932cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['k_proj', 'v_proj', 'q_proj', 'out_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM'\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b0457a-586a-4d29-b551-01bd91214c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_len(col, max_len):\n",
    "    for i in range(len(col)):\n",
    "        if len(col[i]) > max_len:\n",
    "            col[i] = col[i][:max_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438858ab-06b9-4012-800d-925e960d5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_process_data(dataset_id, fields, data_split = 'train'):\n",
    "    data_set = load_dataset(dataset_id)\n",
    "    for field in fields:\n",
    "        cap_len(data_set[data_split][field], 2048)\n",
    "    processed_data = data_set.map(\n",
    "        lambda samples: tokenizer(\n",
    "            *[samples[field] for field in fields]\n",
    "        ),\n",
    "        batched=True\n",
    "    )\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24b05c-e176-47a5-9b9e-00b7a3193396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mental Health\n",
    "#data = import_and_process_data(\n",
    "#    'Amod/mental_health_counseling_conversations',\n",
    "#    ['Context', 'Response']\n",
    "#)\n",
    "\n",
    "# Physics\n",
    "#data = import_and_process_data(\n",
    "#    'camel-ai/physics',\n",
    "#    ['message_1', 'message_2']\n",
    "#)\n",
    "\n",
    "# Biology\n",
    "#data = import_and_process_data(\n",
    "#    'camel-ai/biology',\n",
    "#    ['message_1', 'message_2']\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4c421-c03b-4c2a-9f33-42e0e363329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data['train'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        max_steps=1500,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir='outputs',\n",
    "        optim='paged_adamw_8bit'\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(\n",
    "        tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939d3de-c910-43ef-9bc5-5210da14f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('outputs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
